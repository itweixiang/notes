| 时间      | 事项     | 改动人 |
| --------- | -------- | ------ |
| 2022-3-10 | 规范初版 | 林蔚湘 |
|           |          |        |
|           |          |        |



### 建表

- 根据预估的数据规模，确定分桶的数量，每个桶数据大小应在50M~300M之间。分桶数starrocks默认为10。

  官方推荐的数据大小为100M~1G，但在实际使用中，**大分桶可能会导致compaction内存占用过高，出现明显的峰值**。官方的开发人员解释说，分桶越多，查询性能越高，表的元数据也会更多（内存占用越多）。

- 如无特殊原因，不要手动指定storage_medium

  starrocks支持SSD、HDD，但这不是业务方需要关注的，有可能集群只有HDD，但业务方如果配置了SSD，**将会导致fe找不到SSD而CPU高负荷**。

- 如无特殊原因，尽量将replication_num设置为1

  starrrokcs默认的副本数为3，但是目前生产上的磁盘为高效云盘，只有极小的可能出现数据丢失，数据的安全性有一定保障。而副本数为3时，**会给集群带来较大的压力**，目前的集群资源还是比较少的。

- 

- 

- 

- 

- 

- 





### load任务

- 如无特大数据量，不要增大导入的数据量

  routine load的默认、最小的导入行数为20W，不要一次性导入过多的数据，否则会**导致load内存占用过高，出现明显的峰值**

- 如无特殊原因，尽量不要缩短routine load的摄取间隔

  routine load默认的导入间隔为15s，如果间隔过小，可能会导致compaction处理不过来，**出现`too many tablet version`的异常，严重情况下会导致分区损坏**。

- kafka_broker_list配置需要告知运维根据环境的不同而修改

  kafka_broker_list为kafka的域名地址，虚拟机无法通过域名直连K8S中的kafka，运维的同事通过往阿里云中添加dns记录，实现在虚拟机中通过域名访问kafka。**测试环境，预生产环境，生产环境，对应的kafka域名可能不同，所以需要告知运维进行修改。**

- property.kafka_default_offsets需要注意数据重复，数据丢失的问题

  starrocks依赖了kafka官方推荐的C++客户端，librdkafka，但该SDK的

- 

- 

- 

- 

- 





### 查询

- 
- 
- 
- 
- 
- 
- 
- 
- 
- 

